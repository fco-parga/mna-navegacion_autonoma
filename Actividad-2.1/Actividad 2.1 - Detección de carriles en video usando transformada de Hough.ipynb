{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e207ec3-be6a-437e-ac9e-06bc9c2dfdb9",
   "metadata": {},
   "source": [
    "# **Maestría en Inteligencia Artificial Aplicada**\n",
    "## **Curso: Navegación autónoma**\n",
    "### Tecnológico de Monterrey\n",
    "###  \tDr. David Antonio Torres\n",
    "\n",
    "#### **Actividad 2.1 - Detección de carriles en video usando transformada de Hough**\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9aa2e0-9f1c-4457-93ff-83aaedc66984",
   "metadata": {},
   "source": [
    "**Nombres y matrículas de los integrantes del equipo:**\n",
    "\n",
    "*   Julio Cesar Lynn Jimenez \n",
    "*   Francisco Javier Parga García A01794380\n",
    "*   Carlos Roberto Torres Ferguson \n",
    "*   Fernando Sebastian Sanchez Cardona \n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d9364-0143-473c-89be-eb2fc956d9b9",
   "metadata": {},
   "source": [
    "# Importar librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f47b34-b01c-495d-a8b0-41ab322f3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f94f2e5-6368-4d43-b59c-5851bb7b8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneDetector:\n",
    "    # Constructor de la clase LaneDetector\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Clase para procesar video y detectar líneas\n",
    "        \n",
    "        Métodos:\n",
    "            -region_of_interest:  Método para crear la región de interés para detectar líneas\n",
    "            -draw_lines:          Método para dibujar las líenas detectadas en la región de interés\n",
    "            -process_frame:       Método para procesar cada fotograma\n",
    "            -process_video:       Método para procesar el video\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # Método para aplicar una máscara en la región de interés de la imagen\n",
    "    def region_of_interest(self, img, vertices):\n",
    "        \"\"\"\n",
    "        Método para crear la región de interés para detectar líneas\n",
    "        \n",
    "        Inputs:\n",
    "            -img:      Fotograma de imagen\n",
    "            -vertices: Numpy array con los tuples de 4 vértices de enteros [[(H1,W1), (H2,W2), (H3,W3), (H4,W4)]]\n",
    "            \n",
    "        Outputs:\n",
    "            -masked_image: Imagen con la máscara en la región de interés\n",
    "        \"\"\"\n",
    "        \n",
    "        # Crear una máscara negra del mismo tamaño que la imagen\n",
    "        mask = np.zeros_like(img)\n",
    "        # Definir el color de la máscara que coincide con la región de interés\n",
    "        match_mask_color = 255\n",
    "        # Rellenar la máscara con el color en la región de interés\n",
    "        cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "        # Aplicar la máscara a la imagen\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        # Devolver la imagen con la máscara aplicada\n",
    "        return masked_image\n",
    "\n",
    "    # Método para dibujar líneas en la imagen\n",
    "    def draw_lines(self, img, lines):\n",
    "        \"\"\"\n",
    "        Método para dibujar las líenas detectadas en la región de interés\n",
    "        \n",
    "        Inputs:\n",
    "            -img:   Fotograma de imagen\n",
    "            -lines: arreglo con la transformación de Hough\n",
    "            \n",
    "        Outputs:\n",
    "            -img: Imagen con líneas dibujadas\n",
    "        \"\"\"\n",
    "        \n",
    "        # Crear una copia de la imagen\n",
    "        img = np.copy(img)\n",
    "        # Crear una imagen negra del mismo tamaño que la imagen original\n",
    "        line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "        # Recorrer todas las líneas\n",
    "        for line in lines:\n",
    "            # Recorrer todos los puntos de la línea\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                # Dibujar la línea en la imagen de líneas\n",
    "                cv2.line(line_img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        # Combinar la imagen original con la imagen de líneas\n",
    "        img = cv2.addWeighted(img, 0.8, line_img, 1, 0)\n",
    "        # Devolver la imagen con las líneas dibujadas\n",
    "        return img\n",
    "\n",
    "    # Método para procesar un fotograma (frame) de video y detectar líneas\n",
    "    def process_frame(self, img):\n",
    "        \"\"\"\n",
    "        Método para procesar cada fotograma\n",
    "        \n",
    "        Inputs:\n",
    "            -img:   Fotograma de imagen\n",
    "            \n",
    "        Outputs:\n",
    "            -img_with_lines: Imagen con líneas dibujadas\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Aplicar desenfoque Gaussiano a la imagen en escala de grises\n",
    "        img_blur = cv2.GaussianBlur(gray_img, (3, 3), 0, 0)\n",
    "        # Detectar bordes usando el algoritmo de Canny\n",
    "        img_canny = cv2.Canny(img_blur, 40, 120)\n",
    "        # Obtener las dimensiones de la imagen\n",
    "        height, width = img.shape[:2]\n",
    "        # Definir los vértices de la región de interés\n",
    "        vertices = np.array([[(width*0.1, height), (width*0.4, height*0.6), (width*0.6, height*0.6), (width*0.9, height)]], dtype=np.int32)\n",
    "        # Aplicar la región de interés a la imagen con bordes detectados\n",
    "        img_roi = self.region_of_interest(img_canny, vertices)\n",
    "\n",
    "        # Definir parámetros para la transformada de Hough\n",
    "        rho = 2\n",
    "        theta = np.pi / 180\n",
    "        threshold = 17\n",
    "        min_line_len = 70\n",
    "        max_line_gap = 110\n",
    "        # Aplicar la transformada de Hough para detectar líneas\n",
    "        lines = cv2.HoughLinesP(img_roi, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "\n",
    "        if lines is not None:\n",
    "            img_with_lines = self.draw_lines(img, lines)\n",
    "        else:\n",
    "            img_with_lines = img\n",
    "\n",
    "        return img_with_lines\n",
    "\n",
    "    # Método para procesar un video completo y detectar líneas en cada fotograma (frame)\n",
    "    def process_video(self, input_video_path, output_video_path):\n",
    "        \"\"\"\n",
    "        Método para procesar el video\n",
    "        \n",
    "        Inputs:\n",
    "            -input_video_path:  Archivo de video de entrada\n",
    "            \n",
    "        Outputs:\n",
    "            -output_video_path: Archivo de video de salida con las líneas detectadas y resaltadas en cada fotograma\n",
    "        \"\"\"\n",
    "        \n",
    "        # Leer el video de entrada\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        # Obtener las dimensiones y la tasa de fotogramas del video\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        # Definir el códec y crear el objeto VideoWriter para el video de salida\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "        # Leer y procesar cada fotograma (frame) del video de entrada\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Procesar el fotograma actual y detectar líneas\n",
    "                result_frame = self.process_frame(frame)\n",
    "                # Escribir el fotograma procesado en el video de salida\n",
    "                out.write(result_frame)\n",
    "                # Mostrar el fotograma procesado en una ventana\n",
    "                #cv2.imshow('Processed Frame', result_frame)\n",
    "\n",
    "                # Si se presiona la tecla 'q', interrumpir el procesamiento del video\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            # Si no hay más fotogramas para leer, terminar el procesamiento\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Liberar recursos y cerrar ventanas\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b05958-abf7-4027-a075-46e5bfaf4604",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = 'input/test2_low-res.mp4'\n",
    "output_video_path = 'output/test2_low-res_detect.mp4'\n",
    "lane_detector = LaneDetector()\n",
    "lane_detector.process_video(input_video_path, output_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b9d15-920a-463a-b471-b36995df275f",
   "metadata": {},
   "source": [
    "## Liga para el video en github: \n",
    "\n",
    "\n",
    "https://github.com/fco-parga/mna-navegacion_autonoma/blob/main/Actividad-2.1/output/test2_low-res_detect.mp4 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
